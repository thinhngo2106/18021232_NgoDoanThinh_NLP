{"cells":[{"cell_type":"markdown","metadata":{"id":"pgqzC2cJZlhT"},"source":["# PAR Transformer XL Trainer\n","\n","This notebook is to facilitate training on Google colab, so that you can use a GPU/TPU."]},{"cell_type":"markdown","metadata":{"id":"PT2hjmySZlhX"},"source":["## Colab specific setup"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"1Wk1-CV2ZlhX","executionInfo":{"status":"ok","timestamp":1642164030692,"user_tz":-420,"elapsed":4762,"user":{"displayName":"StudywithT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12146472268166735958"}}},"outputs":[],"source":["%%capture\n","!pip install tensorflow_text"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IUio3gBUZlhY","executionInfo":{"status":"ok","timestamp":1642164032076,"user_tz":-420,"elapsed":1397,"user":{"displayName":"StudywithT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12146472268166735958"}},"outputId":"3aedc62b-69c2-41ae-99c1-a5e76828f22d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'PAR-Transformer-XL'...\n","remote: Enumerating objects: 263, done.\u001b[K\n","remote: Counting objects: 100% (263/263), done.\u001b[K\n","remote: Compressing objects: 100% (160/160), done.\u001b[K\n","remote: Total 263 (delta 130), reused 211 (delta 86), pack-reused 0\u001b[K\n","Receiving objects: 100% (263/263), 11.26 MiB | 23.49 MiB/s, done.\n","Resolving deltas: 100% (130/130), done.\n","/content/PAR-Transformer-XL\n"]}],"source":["!git clone https://github.com/Jmkernes/PAR-Transformer-XL.git\n","%cd PAR-Transformer-XL/"]},{"cell_type":"markdown","metadata":{"id":"bIHEu-A1ZlhZ"},"source":["## Load tensorboard. Re-run this cell before every run to reload tensorboard.\n","\n","This will setup the metric tracking. It's not required, as the code will print out the loss every 100 steps and print to a log file. But, this will tell you additional things like learning rate, perplexity and validation metrics."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aTAo6j4MZlhZ","executionInfo":{"status":"error","timestamp":1642161615692,"user_tz":-420,"elapsed":729,"user":{"displayName":"StudywithT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12146472268166735958"}},"outputId":"28a9caf4-2a68-42cd-ff20-be00a02c5a81"},"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove 'plots': No such file or directory\n"]},{"output_type":"stream","name":"stderr","text":["UsageError: Line magic function `%tensorboard` not found.\n"]}],"source":["!rm -r logs\n","!rm -r plots\n","!mkdir logs\n","%tensorboard --logdir logs"]},{"cell_type":"markdown","metadata":{"id":"7-QvU1eYZlha"},"source":["## Run the model\n","\n","Adjust the parameters in the base_model script if you want to alter the model."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PuhLcEQpZlha","executionInfo":{"status":"ok","timestamp":1642165990338,"user_tz":-420,"elapsed":1491063,"user":{"displayName":"StudywithT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12146472268166735958"}},"outputId":"a2aab619-ebca-44a1-abfb-98049675e8e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== Setting up configuration ===\n","=== Beginning training ===\n","2022-01-14 12:48:18,938 [INFO] \n","\n","~~~~~~~~ Importing Modules ~~~~~~~~\n","\n","I0114 12:48:21.775961 140604169783168 train.py:100] \n","Loading training data from: data/wikitext2_bsz32_seqlen32_tfrecords_train\n","Loading tokenizer from tokenizer/wiki2_12k.model...\n","2022-01-14 12:48:22.477174: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","Loading tfrecords from directory\n","I0114 12:48:22.962116 140604169783168 train.py:104] \n","Loading validation data from: data/wikitext2_bsz32_seqlen32_tfrecords_valid\n","Loading tokenizer from tokenizer/wiki2_12k.model...\n","Loading tfrecords from directory\n","I0114 12:48:23.075972 140604169783168 train.py:108] \n","Loading testing data from: data/wikitext2_bsz32_seqlen32_tfrecords_test\n","\n","Loading tokenizer from tokenizer/wiki2_12k.model...\n","Loading tfrecords from directory\n","I0114 12:48:23.179342 140604169783168 train.py:173] \n","\n","Initializing adam optimizer with 4000 warmup steps.\n","I0114 12:48:23.181767 140604169783168 train.py:207] \n","\n","Initializing model...\n","I0114 12:48:23.181918 140604169783168 train.py:208] Model parameters:\n","I0114 12:48:23.181993 140604169783168 train.py:209] {'d_model': 128, 'num_heads': 4, 'max_position': 512, 'd_ffn': 512, 'num_layers': 6, 'mem_len': 16, 'vocab_size': 12000, 'dropout_rate': 0.1, 'cutoffs': [250, 2500, 12000], 'proj_factor': 4, 'proj_dims': [], 'straight_through': False}\n","I0114 12:48:24.801222 140604169783168 train.py:223] \n","Model summary:\n","Model: \"par_transformer_xl\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       multiple                  1536000   \n","                                                                 \n"," adaptive_softmax (AdaptiveS  multiple                 197418    \n"," oftmax)                                                         \n","                                                                 \n"," stochastic_block (Stochasti  multiple                 215043    \n"," cBlock)                                                         \n","                                                                 \n"," stochastic_block_1 (Stochas  multiple                 215043    \n"," ticBlock)                                                       \n","                                                                 \n"," stochastic_block_2 (Stochas  multiple                 215043    \n"," ticBlock)                                                       \n","                                                                 \n"," stochastic_block_3 (Stochas  multiple                 215043    \n"," ticBlock)                                                       \n","                                                                 \n"," stochastic_block_4 (Stochas  multiple                 215043    \n"," ticBlock)                                                       \n","                                                                 \n"," stochastic_block_5 (Stochas  multiple                 215043    \n"," ticBlock)                                                       \n","                                                                 \n"," inp_dropout (Dropout)       multiple                  0         \n","                                                                 \n","=================================================================\n","Total params: 3,023,676\n","Trainable params: 3,023,676\n","Non-trainable params: 0\n","_________________________________________________________________\n","I0114 12:48:24.806520 140604169783168 train.py:224] None\n","I0114 12:48:24.817169 140604169783168 train.py:232] \n","\n","Defining training and evaluation steps...\n","I0114 12:48:24.817483 140604169783168 train.py:257] \n","\n","Initializing TensorBoard...\n","I0114 12:48:24.818398 140604169783168 train.py:269] \n","\n","Configuring datasets for training. Caching, prefetching...\n","I0114 12:48:24.850826 140604169783168 train.py:277] \n","\n","Initializing checkpoints. Models will be saved to ./checkpoints/train/dmodel128_dffn512_blocks6\n","I0114 12:48:24.927820 140604169783168 train.py:288] Latest checkpoint restored!!\n","I0114 12:48:25.004574 140604169783168 train.py:293] Checkpointing model initialization at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-2\n","I0114 12:48:25.004934 140604169783168 train.py:296] Writing model configuration to ./checkpoints/train/dmodel128_dffn512_blocks6/config\n","I0114 12:48:25.005065 140604169783168 train.py:301] \n","\n","~~~~~~~~~~ Beginning training ~~~~~~~~~~\n","I0114 12:48:25.005164 140604169783168 train.py:304] \n","---------- Epoch 1/20 ----------\n","I0114 12:48:39.051854 140604169783168 train.py:326] Iteration 100/56540: 7.12 it/s. Loss: 8.438\n","I0114 12:48:41.570103 140604169783168 train.py:326] Iteration 200/56540: 12.07 it/s. Loss: 8.371\n","I0114 12:48:44.076292 140604169783168 train.py:326] Iteration 300/56540: 15.73 it/s. Loss: 8.242\n","I0114 12:48:46.551688 140604169783168 train.py:326] Iteration 400/56540: 18.57 it/s. Loss: 8.059\n","I0114 12:48:49.042563 140604169783168 train.py:326] Iteration 500/56540: 20.80 it/s. Loss: 7.867\n","I0114 12:48:51.526611 140604169783168 train.py:326] Iteration 600/56540: 22.62 it/s. Loss: 7.680\n","I0114 12:48:54.017158 140604169783168 train.py:326] Iteration 700/56540: 24.13 it/s. Loss: 7.503\n","I0114 12:48:56.510383 140604169783168 train.py:326] Iteration 800/56540: 25.39 it/s. Loss: 7.350\n","I0114 12:48:58.992712 140604169783168 train.py:326] Iteration 900/56540: 26.48 it/s. Loss: 7.216\n","I0114 12:49:01.455670 140604169783168 train.py:326] Iteration 1000/56540: 27.44 it/s. Loss: 7.101\n","I0114 12:49:03.918009 140604169783168 train.py:326] Iteration 1100/56540: 28.27 it/s. Loss: 6.994\n","I0114 12:49:06.412621 140604169783168 train.py:326] Iteration 1200/56540: 28.98 it/s. Loss: 6.898\n","I0114 12:49:08.891064 140604169783168 train.py:326] Iteration 1300/56540: 29.62 it/s. Loss: 6.816\n","I0114 12:49:11.399556 140604169783168 train.py:326] Iteration 1400/56540: 30.18 it/s. Loss: 6.742\n","I0114 12:49:13.930138 140604169783168 train.py:326] Iteration 1500/56540: 30.66 it/s. Loss: 6.674\n","I0114 12:49:16.404751 140604169783168 train.py:326] Iteration 1600/56540: 31.13 it/s. Loss: 6.611\n","I0114 12:49:18.892639 140604169783168 train.py:326] Iteration 1700/56540: 31.55 it/s. Loss: 6.554\n","I0114 12:49:21.355209 140604169783168 train.py:326] Iteration 1800/56540: 31.94 it/s. Loss: 6.498\n","I0114 12:49:23.826165 140604169783168 train.py:326] Iteration 1900/56540: 32.30 it/s. Loss: 6.445\n","I0114 12:49:26.291197 140604169783168 train.py:326] Iteration 2000/56540: 32.63 it/s. Loss: 6.395\n","I0114 12:49:28.806835 140604169783168 train.py:326] Iteration 2100/56540: 32.92 it/s. Loss: 6.349\n","I0114 12:49:31.297033 140604169783168 train.py:326] Iteration 2200/56540: 33.19 it/s. Loss: 6.305\n","I0114 12:49:33.787030 140604169783168 train.py:326] Iteration 2300/56540: 33.44 it/s. Loss: 6.263\n","I0114 12:49:36.305669 140604169783168 train.py:326] Iteration 2400/56540: 33.66 it/s. Loss: 6.220\n","I0114 12:49:38.791453 140604169783168 train.py:326] Iteration 2500/56540: 33.88 it/s. Loss: 6.180\n","I0114 12:49:41.261824 140604169783168 train.py:326] Iteration 2600/56540: 34.10 it/s. Loss: 6.144\n","I0114 12:49:43.704742 140604169783168 train.py:326] Iteration 2700/56540: 34.31 it/s. Loss: 6.107\n","I0114 12:49:46.228708 140604169783168 train.py:326] Iteration 2800/56540: 34.47 it/s. Loss: 6.071\n","Iteration 2827/2827: [==========>] 34.52 it/s. Est: 00m 00s Loss: 6.061\n","I0114 12:49:53.369190 140604169783168 train.py:351] Saving checkpoint for epoch 1 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-3\n","I0114 12:49:53.369429 140604169783168 train.py:304] \n","---------- Epoch 2/20 ----------\n","I0114 12:49:55.198868 140604169783168 train.py:326] Iteration 2900/56540: 39.92 it/s. Loss: 5.100\n","I0114 12:49:57.703087 140604169783168 train.py:326] Iteration 3000/56540: 39.93 it/s. Loss: 5.096\n","I0114 12:50:00.232764 140604169783168 train.py:326] Iteration 3100/56540: 39.78 it/s. Loss: 5.074\n","I0114 12:50:02.769519 140604169783168 train.py:326] Iteration 3200/56540: 39.68 it/s. Loss: 5.055\n","I0114 12:50:05.266503 140604169783168 train.py:326] Iteration 3300/56540: 39.76 it/s. Loss: 5.048\n","I0114 12:50:07.763342 140604169783168 train.py:326] Iteration 3400/56540: 39.81 it/s. Loss: 5.032\n","I0114 12:50:10.278063 140604169783168 train.py:326] Iteration 3500/56540: 39.80 it/s. Loss: 5.019\n","I0114 12:50:12.794412 140604169783168 train.py:326] Iteration 3600/56540: 39.80 it/s. Loss: 5.002\n","I0114 12:50:15.288210 140604169783168 train.py:326] Iteration 3700/56540: 39.83 it/s. Loss: 4.993\n","I0114 12:50:17.820400 140604169783168 train.py:326] Iteration 3800/56540: 39.80 it/s. Loss: 4.987\n","I0114 12:50:20.317460 140604169783168 train.py:326] Iteration 3900/56540: 39.82 it/s. Loss: 4.976\n","I0114 12:50:22.999434 140604169783168 train.py:326] Iteration 4000/56540: 39.59 it/s. Loss: 4.960\n","I0114 12:50:25.537074 140604169783168 train.py:326] Iteration 4100/56540: 39.58 it/s. Loss: 4.951\n","I0114 12:50:28.102085 140604169783168 train.py:326] Iteration 4200/56540: 39.53 it/s. Loss: 4.944\n","I0114 12:50:30.675169 140604169783168 train.py:326] Iteration 4300/56540: 39.49 it/s. Loss: 4.934\n","I0114 12:50:33.271741 140604169783168 train.py:326] Iteration 4400/56540: 39.42 it/s. Loss: 4.924\n","I0114 12:50:35.843668 140604169783168 train.py:326] Iteration 4500/56540: 39.39 it/s. Loss: 4.917\n","I0114 12:50:38.391640 140604169783168 train.py:326] Iteration 4600/56540: 39.38 it/s. Loss: 4.907\n","I0114 12:50:40.957596 140604169783168 train.py:326] Iteration 4700/56540: 39.36 it/s. Loss: 4.898\n","I0114 12:50:43.480011 140604169783168 train.py:326] Iteration 4800/56540: 39.37 it/s. Loss: 4.887\n","I0114 12:50:46.006296 140604169783168 train.py:326] Iteration 4900/56540: 39.38 it/s. Loss: 4.877\n","I0114 12:50:48.524074 140604169783168 train.py:326] Iteration 5000/56540: 39.40 it/s. Loss: 4.868\n","I0114 12:50:51.054143 140604169783168 train.py:326] Iteration 5100/56540: 39.40 it/s. Loss: 4.858\n","I0114 12:50:53.596439 140604169783168 train.py:326] Iteration 5200/56540: 39.40 it/s. Loss: 4.850\n","I0114 12:50:56.143823 140604169783168 train.py:326] Iteration 5300/56540: 39.40 it/s. Loss: 4.841\n","I0114 12:50:58.645355 140604169783168 train.py:326] Iteration 5400/56540: 39.42 it/s. Loss: 4.833\n","I0114 12:51:01.183900 140604169783168 train.py:326] Iteration 5500/56540: 39.42 it/s. Loss: 4.825\n","I0114 12:51:03.713095 140604169783168 train.py:326] Iteration 5600/56540: 39.42 it/s. Loss: 4.816\n","Iteration 2827/2827: [==========>] 39.45 it/s. Est: 00m 00s Loss: 4.811\n","I0114 12:51:08.196185 140604169783168 train.py:351] Saving checkpoint for epoch 2 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-4\n","I0114 12:51:08.196412 140604169783168 train.py:304] \n","---------- Epoch 3/20 ----------\n","I0114 12:51:09.385834 140604169783168 train.py:326] Iteration 5700/56540: 38.71 it/s. Loss: 4.597\n","I0114 12:51:11.973526 140604169783168 train.py:326] Iteration 5800/56540: 38.66 it/s. Loss: 4.592\n","I0114 12:51:14.550557 140604169783168 train.py:326] Iteration 5900/56540: 38.72 it/s. Loss: 4.579\n","I0114 12:51:17.094422 140604169783168 train.py:326] Iteration 6000/56540: 38.89 it/s. Loss: 4.572\n","I0114 12:51:19.628281 140604169783168 train.py:326] Iteration 6100/56540: 39.02 it/s. Loss: 4.574\n","I0114 12:51:22.181656 140604169783168 train.py:326] Iteration 6200/56540: 39.04 it/s. Loss: 4.566\n","I0114 12:51:24.752465 140604169783168 train.py:326] Iteration 6300/56540: 39.02 it/s. Loss: 4.561\n","I0114 12:51:27.272380 140604169783168 train.py:326] Iteration 6400/56540: 39.11 it/s. Loss: 4.553\n","I0114 12:51:29.767768 140604169783168 train.py:326] Iteration 6500/56540: 39.22 it/s. Loss: 4.545\n","I0114 12:51:32.333895 140604169783168 train.py:326] Iteration 6600/56540: 39.19 it/s. Loss: 4.546\n","I0114 12:51:34.861297 140604169783168 train.py:326] Iteration 6700/56540: 39.23 it/s. Loss: 4.542\n","I0114 12:51:37.416024 140604169783168 train.py:326] Iteration 6800/56540: 39.22 it/s. Loss: 4.535\n","I0114 12:51:39.955217 140604169783168 train.py:326] Iteration 6900/56540: 39.23 it/s. Loss: 4.531\n","I0114 12:51:42.485991 140604169783168 train.py:326] Iteration 7000/56540: 39.25 it/s. Loss: 4.529\n","I0114 12:51:44.980871 140604169783168 train.py:326] Iteration 7100/56540: 39.31 it/s. Loss: 4.525\n","I0114 12:51:47.451647 140604169783168 train.py:326] Iteration 7200/56540: 39.38 it/s. Loss: 4.521\n","I0114 12:51:49.978723 140604169783168 train.py:326] Iteration 7300/56540: 39.40 it/s. Loss: 4.520\n","I0114 12:51:52.474059 140604169783168 train.py:326] Iteration 7400/56540: 39.43 it/s. Loss: 4.517\n","I0114 12:51:54.917543 140604169783168 train.py:326] Iteration 7500/56540: 39.51 it/s. Loss: 4.513\n","I0114 12:51:57.459187 140604169783168 train.py:326] Iteration 7600/56540: 39.50 it/s. Loss: 4.508\n","I0114 12:51:59.961171 140604169783168 train.py:326] Iteration 7700/56540: 39.53 it/s. Loss: 4.503\n","I0114 12:52:02.427353 140604169783168 train.py:326] Iteration 7800/56540: 39.57 it/s. Loss: 4.497\n","I0114 12:52:04.983090 140604169783168 train.py:326] Iteration 7900/56540: 39.55 it/s. Loss: 4.492\n","I0114 12:52:07.487789 140604169783168 train.py:326] Iteration 8000/56540: 39.57 it/s. Loss: 4.489\n","I0114 12:52:09.998464 140604169783168 train.py:326] Iteration 8100/56540: 39.58 it/s. Loss: 4.484\n","I0114 12:52:12.453238 140604169783168 train.py:326] Iteration 8200/56540: 39.62 it/s. Loss: 4.480\n","I0114 12:52:14.948718 140604169783168 train.py:326] Iteration 8300/56540: 39.64 it/s. Loss: 4.477\n","I0114 12:52:17.436686 140604169783168 train.py:326] Iteration 8400/56540: 39.66 it/s. Loss: 4.473\n","Iteration 2827/2827: [==========>] 39.67 it/s. Est: 00m 00s Loss: 4.469\n","I0114 12:52:22.500693 140604169783168 train.py:351] Saving checkpoint for epoch 3 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-5\n","I0114 12:52:22.500910 140604169783168 train.py:304] \n","---------- Epoch 4/20 ----------\n","I0114 12:52:22.992264 140604169783168 train.py:326] Iteration 8500/56540: 38.75 it/s. Loss: 4.362\n","I0114 12:52:25.489761 140604169783168 train.py:326] Iteration 8600/56540: 39.83 it/s. Loss: 4.370\n","I0114 12:52:28.056709 140604169783168 train.py:326] Iteration 8700/56540: 39.43 it/s. Loss: 4.366\n","I0114 12:52:30.677539 140604169783168 train.py:326] Iteration 8800/56540: 39.02 it/s. Loss: 4.358\n","I0114 12:52:33.254816 140604169783168 train.py:326] Iteration 8900/56540: 38.97 it/s. Loss: 4.358\n","I0114 12:52:35.727964 140604169783168 train.py:326] Iteration 9000/56540: 39.24 it/s. Loss: 4.356\n","I0114 12:52:38.242574 140604169783168 train.py:326] Iteration 9100/56540: 39.32 it/s. Loss: 4.350\n","I0114 12:52:40.749380 140604169783168 train.py:326] Iteration 9200/56540: 39.40 it/s. Loss: 4.346\n","I0114 12:52:43.251487 140604169783168 train.py:326] Iteration 9300/56540: 39.47 it/s. Loss: 4.341\n","I0114 12:52:45.737537 140604169783168 train.py:326] Iteration 9400/56540: 39.55 it/s. Loss: 4.342\n","I0114 12:52:48.190511 140604169783168 train.py:326] Iteration 9500/56540: 39.67 it/s. Loss: 4.342\n","I0114 12:52:50.633624 140604169783168 train.py:326] Iteration 9600/56540: 39.78 it/s. Loss: 4.338\n","I0114 12:52:53.096786 140604169783168 train.py:326] Iteration 9700/56540: 39.84 it/s. Loss: 4.334\n","I0114 12:52:55.602933 140604169783168 train.py:326] Iteration 9800/56540: 39.85 it/s. Loss: 4.334\n","I0114 12:52:58.089527 140604169783168 train.py:326] Iteration 9900/56540: 39.87 it/s. Loss: 4.332\n","I0114 12:53:00.587502 140604169783168 train.py:326] Iteration 10000/56540: 39.88 it/s. Loss: 4.330\n","I0114 12:53:03.071321 140604169783168 train.py:326] Iteration 10100/56540: 39.91 it/s. Loss: 4.330\n","I0114 12:53:05.558274 140604169783168 train.py:326] Iteration 10200/56540: 39.92 it/s. Loss: 4.330\n","I0114 12:53:08.045469 140604169783168 train.py:326] Iteration 10300/56540: 39.94 it/s. Loss: 4.327\n","I0114 12:53:10.538488 140604169783168 train.py:326] Iteration 10400/56540: 39.95 it/s. Loss: 4.323\n","I0114 12:53:13.035122 140604169783168 train.py:326] Iteration 10500/56540: 39.95 it/s. Loss: 4.319\n","I0114 12:53:15.528913 140604169783168 train.py:326] Iteration 10600/56540: 39.96 it/s. Loss: 4.314\n","I0114 12:53:18.016161 140604169783168 train.py:326] Iteration 10700/56540: 39.97 it/s. Loss: 4.310\n","I0114 12:53:20.497067 140604169783168 train.py:326] Iteration 10800/56540: 39.99 it/s. Loss: 4.309\n","I0114 12:53:22.963296 140604169783168 train.py:326] Iteration 10900/56540: 40.01 it/s. Loss: 4.306\n","I0114 12:53:25.436125 140604169783168 train.py:326] Iteration 11000/56540: 40.03 it/s. Loss: 4.303\n","I0114 12:53:27.890868 140604169783168 train.py:326] Iteration 11100/56540: 40.05 it/s. Loss: 4.300\n","I0114 12:53:30.369178 140604169783168 train.py:326] Iteration 11200/56540: 40.06 it/s. Loss: 4.298\n","I0114 12:53:32.848003 140604169783168 train.py:326] Iteration 11300/56540: 40.07 it/s. Loss: 4.295\n","Iteration 2827/2827: [==========>] 40.07 it/s. Est: 00m 00s Loss: 4.295\n","I0114 12:53:36.057659 140604169783168 train.py:351] Saving checkpoint for epoch 4 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-6\n","I0114 12:53:36.057876 140604169783168 train.py:304] \n","---------- Epoch 5/20 ----------\n","I0114 12:53:38.364644 140604169783168 train.py:326] Iteration 11400/56540: 39.90 it/s. Loss: 4.230\n","I0114 12:53:40.871467 140604169783168 train.py:326] Iteration 11500/56540: 39.90 it/s. Loss: 4.239\n","I0114 12:53:43.363563 140604169783168 train.py:326] Iteration 11600/56540: 39.97 it/s. Loss: 4.227\n","I0114 12:53:45.854683 140604169783168 train.py:326] Iteration 11700/56540: 40.02 it/s. Loss: 4.224\n","I0114 12:53:48.359539 140604169783168 train.py:326] Iteration 11800/56540: 40.00 it/s. Loss: 4.226\n","I0114 12:53:50.842010 140604169783168 train.py:326] Iteration 11900/56540: 40.05 it/s. Loss: 4.220\n","I0114 12:53:53.322325 140604169783168 train.py:326] Iteration 12000/56540: 40.09 it/s. Loss: 4.219\n","I0114 12:53:55.802722 140604169783168 train.py:326] Iteration 12100/56540: 40.11 it/s. Loss: 4.215\n","I0114 12:53:58.280444 140604169783168 train.py:326] Iteration 12200/56540: 40.14 it/s. Loss: 4.215\n","I0114 12:54:00.776965 140604169783168 train.py:326] Iteration 12300/56540: 40.13 it/s. Loss: 4.217\n","I0114 12:54:03.249511 140604169783168 train.py:326] Iteration 12400/56540: 40.16 it/s. Loss: 4.215\n","I0114 12:54:05.710575 140604169783168 train.py:326] Iteration 12500/56540: 40.20 it/s. Loss: 4.209\n","I0114 12:54:08.179762 140604169783168 train.py:326] Iteration 12600/56540: 40.22 it/s. Loss: 4.210\n","I0114 12:54:10.684623 140604169783168 train.py:326] Iteration 12700/56540: 40.20 it/s. Loss: 4.210\n","I0114 12:54:13.190718 140604169783168 train.py:326] Iteration 12800/56540: 40.18 it/s. Loss: 4.209\n","I0114 12:54:15.664996 140604169783168 train.py:326] Iteration 12900/56540: 40.20 it/s. Loss: 4.208\n","I0114 12:54:18.145854 140604169783168 train.py:326] Iteration 13000/56540: 40.20 it/s. Loss: 4.210\n","I0114 12:54:20.631118 140604169783168 train.py:326] Iteration 13100/56540: 40.20 it/s. Loss: 4.208\n","I0114 12:54:23.127971 140604169783168 train.py:326] Iteration 13200/56540: 40.20 it/s. Loss: 4.206\n","I0114 12:54:25.623847 140604169783168 train.py:326] Iteration 13300/56540: 40.19 it/s. Loss: 4.202\n","I0114 12:54:28.111389 140604169783168 train.py:326] Iteration 13400/56540: 40.19 it/s. Loss: 4.198\n","I0114 12:54:30.619384 140604169783168 train.py:326] Iteration 13500/56540: 40.18 it/s. Loss: 4.194\n","I0114 12:54:33.084789 140604169783168 train.py:326] Iteration 13600/56540: 40.19 it/s. Loss: 4.192\n","I0114 12:54:35.553497 140604169783168 train.py:326] Iteration 13700/56540: 40.21 it/s. Loss: 4.190\n","I0114 12:54:38.043514 140604169783168 train.py:326] Iteration 13800/56540: 40.20 it/s. Loss: 4.188\n","I0114 12:54:40.538578 140604169783168 train.py:326] Iteration 13900/56540: 40.20 it/s. Loss: 4.186\n","I0114 12:54:43.014458 140604169783168 train.py:326] Iteration 14000/56540: 40.21 it/s. Loss: 4.185\n","I0114 12:54:45.500092 140604169783168 train.py:326] Iteration 14100/56540: 40.21 it/s. Loss: 4.183\n","Iteration 2827/2827: [==========>] 40.21 it/s. Est: 00m 00s Loss: 4.181\n","I0114 12:54:49.325903 140604169783168 train.py:351] Saving checkpoint for epoch 5 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-7\n","I0114 12:54:49.326135 140604169783168 train.py:304] \n","---------- Epoch 6/20 ----------\n","I0114 12:54:50.936871 140604169783168 train.py:326] Iteration 14200/56540: 40.38 it/s. Loss: 4.136\n","I0114 12:54:53.398572 140604169783168 train.py:326] Iteration 14300/56540: 40.53 it/s. Loss: 4.142\n","I0114 12:54:55.849580 140604169783168 train.py:326] Iteration 14400/56540: 40.63 it/s. Loss: 4.132\n","I0114 12:54:58.341712 140604169783168 train.py:326] Iteration 14500/56540: 40.49 it/s. Loss: 4.129\n","I0114 12:55:00.797100 140604169783168 train.py:326] Iteration 14600/56540: 40.54 it/s. Loss: 4.133\n","I0114 12:55:03.268341 140604169783168 train.py:326] Iteration 14700/56540: 40.53 it/s. Loss: 4.129\n","I0114 12:55:05.801403 140604169783168 train.py:326] Iteration 14800/56540: 40.37 it/s. Loss: 4.128\n","I0114 12:55:08.250623 140604169783168 train.py:326] Iteration 14900/56540: 40.43 it/s. Loss: 4.124\n","I0114 12:55:10.716311 140604169783168 train.py:326] Iteration 15000/56540: 40.44 it/s. Loss: 4.122\n","I0114 12:55:13.226342 140604169783168 train.py:326] Iteration 15100/56540: 40.38 it/s. Loss: 4.126\n","I0114 12:55:15.764750 140604169783168 train.py:326] Iteration 15200/56540: 40.28 it/s. Loss: 4.126\n","I0114 12:55:18.287366 140604169783168 train.py:326] Iteration 15300/56540: 40.23 it/s. Loss: 4.121\n","I0114 12:55:20.726000 140604169783168 train.py:326] Iteration 15400/56540: 40.29 it/s. Loss: 4.120\n","I0114 12:55:23.233252 140604169783168 train.py:326] Iteration 15500/56540: 40.26 it/s. Loss: 4.121\n","I0114 12:55:25.799918 140604169783168 train.py:326] Iteration 15600/56540: 40.17 it/s. Loss: 4.121\n","I0114 12:55:28.261343 140604169783168 train.py:326] Iteration 15700/56540: 40.20 it/s. Loss: 4.120\n","I0114 12:55:30.722885 140604169783168 train.py:326] Iteration 15800/56540: 40.22 it/s. Loss: 4.123\n","I0114 12:55:33.216549 140604169783168 train.py:326] Iteration 15900/56540: 40.21 it/s. Loss: 4.122\n","I0114 12:55:35.683529 140604169783168 train.py:326] Iteration 16000/56540: 40.23 it/s. Loss: 4.121\n","I0114 12:55:38.173371 140604169783168 train.py:326] Iteration 16100/56540: 40.23 it/s. Loss: 4.117\n","I0114 12:55:40.649134 140604169783168 train.py:326] Iteration 16200/56540: 40.24 it/s. Loss: 4.113\n","I0114 12:55:43.110150 140604169783168 train.py:326] Iteration 16300/56540: 40.25 it/s. Loss: 4.109\n","I0114 12:55:45.591235 140604169783168 train.py:326] Iteration 16400/56540: 40.26 it/s. Loss: 4.107\n","I0114 12:55:48.092551 140604169783168 train.py:326] Iteration 16500/56540: 40.24 it/s. Loss: 4.106\n","I0114 12:55:50.561464 140604169783168 train.py:326] Iteration 16600/56540: 40.26 it/s. Loss: 4.104\n","I0114 12:55:53.020816 140604169783168 train.py:326] Iteration 16700/56540: 40.27 it/s. Loss: 4.102\n","I0114 12:55:55.535393 140604169783168 train.py:326] Iteration 16800/56540: 40.25 it/s. Loss: 4.101\n","I0114 12:55:58.013198 140604169783168 train.py:326] Iteration 16900/56540: 40.26 it/s. Loss: 4.099\n","Iteration 2827/2827: [==========>] 40.25 it/s. Est: 00m 00s Loss: 4.098\n","I0114 12:56:02.565792 140604169783168 train.py:351] Saving checkpoint for epoch 6 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-8\n","I0114 12:56:02.566067 140604169783168 train.py:304] \n","---------- Epoch 7/20 ----------\n","I0114 12:56:03.518270 140604169783168 train.py:326] Iteration 17000/56540: 39.96 it/s. Loss: 4.052\n","I0114 12:56:06.006599 140604169783168 train.py:326] Iteration 17100/56540: 40.12 it/s. Loss: 4.067\n","I0114 12:56:08.542889 140604169783168 train.py:326] Iteration 17200/56540: 39.83 it/s. Loss: 4.068\n","I0114 12:56:11.031008 140604169783168 train.py:326] Iteration 17300/56540: 39.93 it/s. Loss: 4.058\n","I0114 12:56:13.487534 140604169783168 train.py:326] Iteration 17400/56540: 40.11 it/s. Loss: 4.063\n","I0114 12:56:15.976860 140604169783168 train.py:326] Iteration 17500/56540: 40.12 it/s. Loss: 4.057\n","I0114 12:56:18.459553 140604169783168 train.py:326] Iteration 17600/56540: 40.14 it/s. Loss: 4.056\n","I0114 12:56:20.957513 140604169783168 train.py:326] Iteration 17700/56540: 40.13 it/s. Loss: 4.055\n","I0114 12:56:23.459518 140604169783168 train.py:326] Iteration 17800/56540: 40.11 it/s. Loss: 4.051\n","I0114 12:56:25.917334 140604169783168 train.py:326] Iteration 17900/56540: 40.17 it/s. Loss: 4.055\n","I0114 12:56:28.408847 140604169783168 train.py:326] Iteration 18000/56540: 40.17 it/s. Loss: 4.056\n","I0114 12:56:30.919444 140604169783168 train.py:326] Iteration 18100/56540: 40.14 it/s. Loss: 4.053\n","I0114 12:56:33.456895 140604169783168 train.py:326] Iteration 18200/56540: 40.08 it/s. Loss: 4.050\n","I0114 12:56:35.934761 140604169783168 train.py:326] Iteration 18300/56540: 40.10 it/s. Loss: 4.051\n","I0114 12:56:38.418782 140604169783168 train.py:326] Iteration 18400/56540: 40.11 it/s. Loss: 4.051\n","I0114 12:56:40.960846 140604169783168 train.py:326] Iteration 18500/56540: 40.06 it/s. Loss: 4.051\n","I0114 12:56:43.434442 140604169783168 train.py:326] Iteration 18600/56540: 40.08 it/s. Loss: 4.053\n","I0114 12:56:45.919085 140604169783168 train.py:326] Iteration 18700/56540: 40.09 it/s. Loss: 4.053\n","I0114 12:56:48.417439 140604169783168 train.py:326] Iteration 18800/56540: 40.09 it/s. Loss: 4.052\n","I0114 12:56:50.912907 140604169783168 train.py:326] Iteration 18900/56540: 40.09 it/s. Loss: 4.049\n","I0114 12:56:53.367433 140604169783168 train.py:326] Iteration 19000/56540: 40.12 it/s. Loss: 4.045\n","I0114 12:56:55.877053 140604169783168 train.py:326] Iteration 19100/56540: 40.11 it/s. Loss: 4.041\n","I0114 12:56:58.342502 140604169783168 train.py:326] Iteration 19200/56540: 40.13 it/s. Loss: 4.038\n","I0114 12:57:00.837474 140604169783168 train.py:326] Iteration 19300/56540: 40.12 it/s. Loss: 4.038\n","I0114 12:57:03.302620 140604169783168 train.py:326] Iteration 19400/56540: 40.14 it/s. Loss: 4.035\n","I0114 12:57:05.819859 140604169783168 train.py:326] Iteration 19500/56540: 40.12 it/s. Loss: 4.034\n","I0114 12:57:08.295146 140604169783168 train.py:326] Iteration 19600/56540: 40.14 it/s. Loss: 4.033\n","I0114 12:57:10.775877 140604169783168 train.py:326] Iteration 19700/56540: 40.14 it/s. Loss: 4.032\n","Iteration 2827/2827: [==========>] 40.15 it/s. Est: 00m 00s Loss: 4.030\n","I0114 12:57:15.927708 140604169783168 train.py:351] Saving checkpoint for epoch 7 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-9\n","I0114 12:57:15.927922 140604169783168 train.py:304] \n","---------- Epoch 8/20 ----------\n","I0114 12:57:16.210783 140604169783168 train.py:326] Iteration 19800/56540: 39.02 it/s. Loss: 3.959\n","I0114 12:57:18.679996 140604169783168 train.py:326] Iteration 19900/56540: 40.35 it/s. Loss: 4.001\n","I0114 12:57:21.163574 140604169783168 train.py:326] Iteration 20000/56540: 40.31 it/s. Loss: 4.007\n","I0114 12:57:23.665641 140604169783168 train.py:326] Iteration 20100/56540: 40.20 it/s. Loss: 3.998\n","I0114 12:57:26.157362 140604169783168 train.py:326] Iteration 20200/56540: 40.18 it/s. Loss: 3.998\n","I0114 12:57:28.735399 140604169783168 train.py:326] Iteration 20300/56540: 39.90 it/s. Loss: 3.996\n","I0114 12:57:31.273638 140604169783168 train.py:326] Iteration 20400/56540: 39.82 it/s. Loss: 3.994\n","I0114 12:57:33.828129 140604169783168 train.py:326] Iteration 20500/56540: 39.72 it/s. Loss: 3.991\n","I0114 12:57:36.347552 140604169783168 train.py:326] Iteration 20600/56540: 39.72 it/s. Loss: 3.989\n","I0114 12:57:38.890678 140604169783168 train.py:326] Iteration 20700/56540: 39.67 it/s. Loss: 3.990\n","I0114 12:57:41.443771 140604169783168 train.py:326] Iteration 20800/56540: 39.62 it/s. Loss: 3.994\n","I0114 12:57:43.933897 140604169783168 train.py:326] Iteration 20900/56540: 39.68 it/s. Loss: 3.991\n","I0114 12:57:46.433848 140604169783168 train.py:326] Iteration 21000/56540: 39.70 it/s. Loss: 3.988\n","I0114 12:57:48.895823 140604169783168 train.py:326] Iteration 21100/56540: 39.77 it/s. Loss: 3.990\n","I0114 12:57:51.351041 140604169783168 train.py:326] Iteration 21200/56540: 39.83 it/s. Loss: 3.989\n","I0114 12:57:53.813062 140604169783168 train.py:326] Iteration 21300/56540: 39.88 it/s. Loss: 3.989\n","I0114 12:57:56.285393 140604169783168 train.py:326] Iteration 21400/56540: 39.92 it/s. Loss: 3.990\n","I0114 12:57:58.777193 140604169783168 train.py:326] Iteration 21500/56540: 39.93 it/s. Loss: 3.992\n","I0114 12:58:01.325452 140604169783168 train.py:326] Iteration 21600/56540: 39.89 it/s. Loss: 3.991\n","I0114 12:58:03.812726 140604169783168 train.py:326] Iteration 21700/56540: 39.91 it/s. Loss: 3.988\n","I0114 12:58:06.309220 140604169783168 train.py:326] Iteration 21800/56540: 39.92 it/s. Loss: 3.985\n","I0114 12:58:08.829572 140604169783168 train.py:326] Iteration 21900/56540: 39.90 it/s. Loss: 3.981\n","I0114 12:58:11.317295 140604169783168 train.py:326] Iteration 22000/56540: 39.92 it/s. Loss: 3.977\n","I0114 12:58:13.774219 140604169783168 train.py:326] Iteration 22100/56540: 39.95 it/s. Loss: 3.977\n","I0114 12:58:16.269930 140604169783168 train.py:326] Iteration 22200/56540: 39.96 it/s. Loss: 3.976\n","I0114 12:58:18.741447 140604169783168 train.py:326] Iteration 22300/56540: 39.98 it/s. Loss: 3.973\n","I0114 12:58:21.222053 140604169783168 train.py:326] Iteration 22400/56540: 39.99 it/s. Loss: 3.973\n","I0114 12:58:23.702857 140604169783168 train.py:326] Iteration 22500/56540: 40.00 it/s. Loss: 3.972\n","I0114 12:58:26.188445 140604169783168 train.py:326] Iteration 22600/56540: 40.01 it/s. Loss: 3.971\n","Iteration 2827/2827: [==========>] 40.02 it/s. Est: 00m 00s Loss: 3.970\n","I0114 12:58:29.535573 140604169783168 train.py:351] Saving checkpoint for epoch 8 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-10\n","I0114 12:58:29.535795 140604169783168 train.py:304] \n","---------- Epoch 9/20 ----------\n","I0114 12:58:31.620535 140604169783168 train.py:326] Iteration 22700/56540: 40.31 it/s. Loss: 3.930\n","I0114 12:58:34.160472 140604169783168 train.py:326] Iteration 22800/56540: 39.79 it/s. Loss: 3.947\n","I0114 12:58:36.649605 140604169783168 train.py:326] Iteration 22900/56540: 39.93 it/s. Loss: 3.942\n","I0114 12:58:39.171592 140604169783168 train.py:326] Iteration 23000/56540: 39.86 it/s. Loss: 3.939\n","I0114 12:58:41.728895 140604169783168 train.py:326] Iteration 23100/56540: 39.70 it/s. Loss: 3.942\n","I0114 12:58:44.199918 140604169783168 train.py:326] Iteration 23200/56540: 39.83 it/s. Loss: 3.938\n","I0114 12:58:46.681732 140604169783168 train.py:326] Iteration 23300/56540: 39.90 it/s. Loss: 3.938\n","I0114 12:58:49.183467 140604169783168 train.py:326] Iteration 23400/56540: 39.90 it/s. Loss: 3.937\n","I0114 12:58:51.679640 140604169783168 train.py:326] Iteration 23500/56540: 39.92 it/s. Loss: 3.936\n","I0114 12:58:54.131943 140604169783168 train.py:326] Iteration 23600/56540: 40.01 it/s. Loss: 3.939\n","I0114 12:58:56.649155 140604169783168 train.py:326] Iteration 23700/56540: 39.98 it/s. Loss: 3.939\n","I0114 12:58:59.123594 140604169783168 train.py:326] Iteration 23800/56540: 40.02 it/s. Loss: 3.934\n","I0114 12:59:01.595745 140604169783168 train.py:326] Iteration 23900/56540: 40.05 it/s. Loss: 3.934\n","I0114 12:59:04.068969 140604169783168 train.py:326] Iteration 24000/56540: 40.08 it/s. Loss: 3.935\n","I0114 12:59:06.569772 140604169783168 train.py:326] Iteration 24100/56540: 40.07 it/s. Loss: 3.935\n","I0114 12:59:09.076763 140604169783168 train.py:326] Iteration 24200/56540: 40.06 it/s. Loss: 3.936\n","I0114 12:59:11.549968 140604169783168 train.py:326] Iteration 24300/56540: 40.08 it/s. Loss: 3.939\n","I0114 12:59:14.033440 140604169783168 train.py:326] Iteration 24400/56540: 40.09 it/s. Loss: 3.938\n","I0114 12:59:16.528119 140604169783168 train.py:326] Iteration 24500/56540: 40.09 it/s. Loss: 3.937\n","I0114 12:59:19.007240 140604169783168 train.py:326] Iteration 24600/56540: 40.10 it/s. Loss: 3.934\n","I0114 12:59:21.453044 140604169783168 train.py:326] Iteration 24700/56540: 40.14 it/s. Loss: 3.930\n","I0114 12:59:23.930211 140604169783168 train.py:326] Iteration 24800/56540: 40.15 it/s. Loss: 3.926\n","I0114 12:59:26.441641 140604169783168 train.py:326] Iteration 24900/56540: 40.14 it/s. Loss: 3.925\n","I0114 12:59:28.927981 140604169783168 train.py:326] Iteration 25000/56540: 40.14 it/s. Loss: 3.924\n","I0114 12:59:31.438533 140604169783168 train.py:326] Iteration 25100/56540: 40.13 it/s. Loss: 3.922\n","I0114 12:59:33.913097 140604169783168 train.py:326] Iteration 25200/56540: 40.14 it/s. Loss: 3.921\n","I0114 12:59:36.419475 140604169783168 train.py:326] Iteration 25300/56540: 40.13 it/s. Loss: 3.921\n","I0114 12:59:38.917814 140604169783168 train.py:326] Iteration 25400/56540: 40.13 it/s. Loss: 3.920\n","Iteration 2827/2827: [==========>] 40.12 it/s. Est: 00m 00s Loss: 3.919\n","I0114 12:59:42.974699 140604169783168 train.py:351] Saving checkpoint for epoch 9 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-11\n","I0114 12:59:42.974929 140604169783168 train.py:304] \n","---------- Epoch 10/20 ----------\n","I0114 12:59:44.418588 140604169783168 train.py:326] Iteration 25500/56540: 39.51 it/s. Loss: 3.889\n","I0114 12:59:46.931834 140604169783168 train.py:326] Iteration 25600/56540: 39.69 it/s. Loss: 3.901\n","I0114 12:59:49.378773 140604169783168 train.py:326] Iteration 25700/56540: 40.14 it/s. Loss: 3.893\n","I0114 12:59:51.883759 140604169783168 train.py:326] Iteration 25800/56540: 40.08 it/s. Loss: 3.888\n","I0114 12:59:54.384152 140604169783168 train.py:326] Iteration 25900/56540: 40.06 it/s. Loss: 3.894\n","I0114 12:59:56.862618 140604169783168 train.py:326] Iteration 26000/56540: 40.11 it/s. Loss: 3.891\n","I0114 12:59:59.339946 140604169783168 train.py:326] Iteration 26100/56540: 40.15 it/s. Loss: 3.891\n","I0114 13:00:01.844821 140604169783168 train.py:326] Iteration 26200/56540: 40.12 it/s. Loss: 3.890\n","I0114 13:00:04.370650 140604169783168 train.py:326] Iteration 26300/56540: 40.06 it/s. Loss: 3.888\n","I0114 13:00:06.858669 140604169783168 train.py:326] Iteration 26400/56540: 40.07 it/s. Loss: 3.892\n","I0114 13:00:09.328588 140604169783168 train.py:326] Iteration 26500/56540: 40.11 it/s. Loss: 3.894\n","I0114 13:00:11.872061 140604169783168 train.py:326] Iteration 26600/56540: 40.04 it/s. Loss: 3.890\n","I0114 13:00:14.366198 140604169783168 train.py:326] Iteration 26700/56540: 40.04 it/s. Loss: 3.888\n","I0114 13:00:16.834948 140604169783168 train.py:326] Iteration 26800/56540: 40.08 it/s. Loss: 3.890\n","I0114 13:00:19.305218 140604169783168 train.py:326] Iteration 26900/56540: 40.11 it/s. Loss: 3.891\n","I0114 13:00:21.787421 140604169783168 train.py:326] Iteration 27000/56540: 40.12 it/s. Loss: 3.891\n","I0114 13:00:24.285393 140604169783168 train.py:326] Iteration 27100/56540: 40.11 it/s. Loss: 3.894\n","I0114 13:00:26.757326 140604169783168 train.py:326] Iteration 27200/56540: 40.13 it/s. Loss: 3.893\n","I0114 13:00:29.230939 140604169783168 train.py:326] Iteration 27300/56540: 40.15 it/s. Loss: 3.893\n","I0114 13:00:31.729276 140604169783168 train.py:326] Iteration 27400/56540: 40.14 it/s. Loss: 3.891\n","I0114 13:00:34.198608 140604169783168 train.py:326] Iteration 27500/56540: 40.16 it/s. Loss: 3.887\n","I0114 13:00:36.707012 140604169783168 train.py:326] Iteration 27600/56540: 40.14 it/s. Loss: 3.883\n","I0114 13:00:39.228953 140604169783168 train.py:326] Iteration 27700/56540: 40.12 it/s. Loss: 3.881\n","I0114 13:00:41.733599 140604169783168 train.py:326] Iteration 27800/56540: 40.11 it/s. Loss: 3.881\n","I0114 13:00:44.230805 140604169783168 train.py:326] Iteration 27900/56540: 40.11 it/s. Loss: 3.879\n","I0114 13:00:46.709906 140604169783168 train.py:326] Iteration 28000/56540: 40.12 it/s. Loss: 3.878\n","I0114 13:00:49.166454 140604169783168 train.py:326] Iteration 28100/56540: 40.14 it/s. Loss: 3.877\n","I0114 13:00:51.660329 140604169783168 train.py:326] Iteration 28200/56540: 40.14 it/s. Loss: 3.877\n","Iteration 2827/2827: [==========>] 40.15 it/s. Est: 00m 00s Loss: 3.876\n","I0114 13:00:56.355749 140604169783168 train.py:351] Saving checkpoint for epoch 10 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-12\n","I0114 13:00:56.355958 140604169783168 train.py:304] \n","---------- Epoch 11/20 ----------\n","I0114 13:00:57.116154 140604169783168 train.py:326] Iteration 28300/56540: 39.51 it/s. Loss: 3.828\n","I0114 13:00:59.567664 140604169783168 train.py:326] Iteration 28400/56540: 40.49 it/s. Loss: 3.857\n","I0114 13:01:02.084105 140604169783168 train.py:326] Iteration 28500/56540: 40.16 it/s. Loss: 3.863\n","I0114 13:01:04.547712 140604169783168 train.py:326] Iteration 28600/56540: 40.29 it/s. Loss: 3.849\n","I0114 13:01:07.037044 140604169783168 train.py:326] Iteration 28700/56540: 40.26 it/s. Loss: 3.853\n","I0114 13:01:09.524952 140604169783168 train.py:326] Iteration 28800/56540: 40.25 it/s. Loss: 3.853\n","I0114 13:01:11.971721 140604169783168 train.py:326] Iteration 28900/56540: 40.35 it/s. Loss: 3.852\n","I0114 13:01:14.443591 140604169783168 train.py:326] Iteration 29000/56540: 40.36 it/s. Loss: 3.853\n","I0114 13:01:16.907193 140604169783168 train.py:326] Iteration 29100/56540: 40.39 it/s. Loss: 3.851\n","I0114 13:01:19.405570 140604169783168 train.py:326] Iteration 29200/56540: 40.35 it/s. Loss: 3.854\n","I0114 13:01:21.906375 140604169783168 train.py:326] Iteration 29300/56540: 40.31 it/s. Loss: 3.857\n","I0114 13:01:24.508006 140604169783168 train.py:326] Iteration 29400/56540: 40.14 it/s. Loss: 3.855\n","I0114 13:01:27.069982 140604169783168 train.py:326] Iteration 29500/56540: 40.05 it/s. Loss: 3.852\n","I0114 13:01:29.551440 140604169783168 train.py:326] Iteration 29600/56540: 40.07 it/s. Loss: 3.853\n","I0114 13:01:32.063631 140604169783168 train.py:326] Iteration 29700/56540: 40.05 it/s. Loss: 3.854\n","I0114 13:01:34.544632 140604169783168 train.py:326] Iteration 29800/56540: 40.07 it/s. Loss: 3.854\n","I0114 13:01:37.020676 140604169783168 train.py:326] Iteration 29900/56540: 40.08 it/s. Loss: 3.856\n","I0114 13:01:39.520637 140604169783168 train.py:326] Iteration 30000/56540: 40.08 it/s. Loss: 3.858\n","I0114 13:01:42.031386 140604169783168 train.py:326] Iteration 30100/56540: 40.07 it/s. Loss: 3.858\n","I0114 13:01:44.513037 140604169783168 train.py:326] Iteration 30200/56540: 40.08 it/s. Loss: 3.855\n","I0114 13:01:47.152125 140604169783168 train.py:326] Iteration 30300/56540: 39.96 it/s. Loss: 3.853\n","I0114 13:01:49.647146 140604169783168 train.py:326] Iteration 30400/56540: 39.97 it/s. Loss: 3.849\n","I0114 13:01:52.156321 140604169783168 train.py:326] Iteration 30500/56540: 39.96 it/s. Loss: 3.845\n","I0114 13:01:54.672932 140604169783168 train.py:326] Iteration 30600/56540: 39.95 it/s. Loss: 3.846\n","I0114 13:01:57.201042 140604169783168 train.py:326] Iteration 30700/56540: 39.94 it/s. Loss: 3.844\n","I0114 13:01:59.738060 140604169783168 train.py:326] Iteration 30800/56540: 39.92 it/s. Loss: 3.843\n","I0114 13:02:02.269707 140604169783168 train.py:326] Iteration 30900/56540: 39.90 it/s. Loss: 3.842\n","I0114 13:02:04.813581 140604169783168 train.py:326] Iteration 31000/56540: 39.88 it/s. Loss: 3.842\n","Iteration 2827/2827: [==========>] 39.83 it/s. Est: 00m 00s Loss: 3.841\n","I0114 13:02:10.365529 140604169783168 train.py:351] Saving checkpoint for epoch 11 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-13\n","I0114 13:02:10.365741 140604169783168 train.py:304] \n","---------- Epoch 12/20 ----------\n","I0114 13:02:10.449412 140604169783168 train.py:326] Iteration 31100/56540: 36.30 it/s. Loss: 3.904\n","I0114 13:02:12.993660 140604169783168 train.py:326] Iteration 31200/56540: 39.21 it/s. Loss: 3.818\n","I0114 13:02:15.593446 140604169783168 train.py:326] Iteration 31300/56540: 38.84 it/s. Loss: 3.829\n","I0114 13:02:18.150835 140604169783168 train.py:326] Iteration 31400/56540: 38.93 it/s. Loss: 3.824\n","I0114 13:02:20.687676 140604169783168 train.py:326] Iteration 31500/56540: 39.05 it/s. Loss: 3.821\n","I0114 13:02:23.278200 140604169783168 train.py:326] Iteration 31600/56540: 38.96 it/s. Loss: 3.821\n","I0114 13:02:25.777044 140604169783168 train.py:326] Iteration 31700/56540: 39.13 it/s. Loss: 3.822\n","I0114 13:02:28.261954 140604169783168 train.py:326] Iteration 31800/56540: 39.28 it/s. Loss: 3.822\n","I0114 13:02:30.746074 140604169783168 train.py:326] Iteration 31900/56540: 39.40 it/s. Loss: 3.822\n","I0114 13:02:33.271251 140604169783168 train.py:326] Iteration 32000/56540: 39.42 it/s. Loss: 3.822\n","I0114 13:02:35.754025 140604169783168 train.py:326] Iteration 32100/56540: 39.51 it/s. Loss: 3.826\n","I0114 13:02:38.245812 140604169783168 train.py:326] Iteration 32200/56540: 39.56 it/s. Loss: 3.824\n","I0114 13:02:40.824920 140604169783168 train.py:326] Iteration 32300/56540: 39.50 it/s. Loss: 3.821\n","I0114 13:02:43.340282 140604169783168 train.py:326] Iteration 32400/56540: 39.52 it/s. Loss: 3.823\n","I0114 13:02:45.874074 140604169783168 train.py:326] Iteration 32500/56540: 39.51 it/s. Loss: 3.823\n","I0114 13:02:48.396587 140604169783168 train.py:326] Iteration 32600/56540: 39.52 it/s. Loss: 3.824\n","I0114 13:02:50.929751 140604169783168 train.py:326] Iteration 32700/56540: 39.52 it/s. Loss: 3.826\n","I0114 13:02:53.460201 140604169783168 train.py:326] Iteration 32800/56540: 39.52 it/s. Loss: 3.829\n","I0114 13:02:55.960656 140604169783168 train.py:326] Iteration 32900/56540: 39.54 it/s. Loss: 3.829\n","I0114 13:02:58.450373 140604169783168 train.py:326] Iteration 33000/56540: 39.58 it/s. Loss: 3.827\n","I0114 13:03:00.943961 140604169783168 train.py:326] Iteration 33100/56540: 39.60 it/s. Loss: 3.824\n","I0114 13:03:03.440740 140604169783168 train.py:326] Iteration 33200/56540: 39.62 it/s. Loss: 3.820\n","I0114 13:03:05.967905 140604169783168 train.py:326] Iteration 33300/56540: 39.62 it/s. Loss: 3.817\n","I0114 13:03:08.429802 140604169783168 train.py:326] Iteration 33400/56540: 39.66 it/s. Loss: 3.817\n","I0114 13:03:10.885434 140604169783168 train.py:326] Iteration 33500/56540: 39.71 it/s. Loss: 3.816\n","I0114 13:03:13.374453 140604169783168 train.py:326] Iteration 33600/56540: 39.73 it/s. Loss: 3.814\n","I0114 13:03:15.848012 140604169783168 train.py:326] Iteration 33700/56540: 39.75 it/s. Loss: 3.814\n","I0114 13:03:18.349337 140604169783168 train.py:326] Iteration 33800/56540: 39.76 it/s. Loss: 3.814\n","I0114 13:03:20.791361 140604169783168 train.py:326] Iteration 33900/56540: 39.80 it/s. Loss: 3.813\n","Iteration 2827/2827: [==========>] 39.80 it/s. Est: 00m 00s Loss: 3.813\n","I0114 13:03:24.346286 140604169783168 train.py:351] Saving checkpoint for epoch 12 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-14\n","I0114 13:03:24.346498 140604169783168 train.py:304] \n","---------- Epoch 13/20 ----------\n","I0114 13:03:26.222513 140604169783168 train.py:326] Iteration 34000/56540: 40.53 it/s. Loss: 3.790\n","I0114 13:03:28.696178 140604169783168 train.py:326] Iteration 34100/56540: 40.47 it/s. Loss: 3.800\n","I0114 13:03:31.196872 140604169783168 train.py:326] Iteration 34200/56540: 40.29 it/s. Loss: 3.797\n","I0114 13:03:33.683818 140604169783168 train.py:326] Iteration 34300/56540: 40.27 it/s. Loss: 3.793\n","I0114 13:03:36.177678 140604169783168 train.py:326] Iteration 34400/56540: 40.24 it/s. Loss: 3.798\n","I0114 13:03:38.635809 140604169783168 train.py:326] Iteration 34500/56540: 40.31 it/s. Loss: 3.796\n","I0114 13:03:41.121720 140604169783168 train.py:326] Iteration 34600/56540: 40.30 it/s. Loss: 3.798\n","I0114 13:03:43.583641 140604169783168 train.py:326] Iteration 34700/56540: 40.34 it/s. Loss: 3.798\n","I0114 13:03:46.064766 140604169783168 train.py:326] Iteration 34800/56540: 40.34 it/s. Loss: 3.798\n","I0114 13:03:48.525283 140604169783168 train.py:326] Iteration 34900/56540: 40.37 it/s. Loss: 3.802\n","I0114 13:03:51.013066 140604169783168 train.py:326] Iteration 35000/56540: 40.35 it/s. Loss: 3.803\n","I0114 13:03:53.462511 140604169783168 train.py:326] Iteration 35100/56540: 40.39 it/s. Loss: 3.798\n","I0114 13:03:55.905036 140604169783168 train.py:326] Iteration 35200/56540: 40.43 it/s. Loss: 3.798\n","I0114 13:03:58.372167 140604169783168 train.py:326] Iteration 35300/56540: 40.44 it/s. Loss: 3.800\n","I0114 13:04:00.852483 140604169783168 train.py:326] Iteration 35400/56540: 40.43 it/s. Loss: 3.802\n","I0114 13:04:03.354768 140604169783168 train.py:326] Iteration 35500/56540: 40.40 it/s. Loss: 3.802\n","I0114 13:04:05.831643 140604169783168 train.py:326] Iteration 35600/56540: 40.40 it/s. Loss: 3.806\n","I0114 13:04:08.295313 140604169783168 train.py:326] Iteration 35700/56540: 40.41 it/s. Loss: 3.806\n","I0114 13:04:10.753011 140604169783168 train.py:326] Iteration 35800/56540: 40.43 it/s. Loss: 3.805\n","I0114 13:04:13.222990 140604169783168 train.py:326] Iteration 35900/56540: 40.43 it/s. Loss: 3.803\n","I0114 13:04:15.695321 140604169783168 train.py:326] Iteration 36000/56540: 40.43 it/s. Loss: 3.799\n","I0114 13:04:18.136540 140604169783168 train.py:326] Iteration 36100/56540: 40.45 it/s. Loss: 3.796\n","I0114 13:04:20.597555 140604169783168 train.py:326] Iteration 36200/56540: 40.46 it/s. Loss: 3.795\n","I0114 13:04:23.032640 140604169783168 train.py:326] Iteration 36300/56540: 40.49 it/s. Loss: 3.795\n","I0114 13:04:25.462952 140604169783168 train.py:326] Iteration 36400/56540: 40.51 it/s. Loss: 3.793\n","I0114 13:04:27.906627 140604169783168 train.py:326] Iteration 36500/56540: 40.53 it/s. Loss: 3.792\n","I0114 13:04:30.348509 140604169783168 train.py:326] Iteration 36600/56540: 40.54 it/s. Loss: 3.792\n","I0114 13:04:32.803087 140604169783168 train.py:326] Iteration 36700/56540: 40.55 it/s. Loss: 3.792\n","Iteration 2827/2827: [==========>] 40.56 it/s. Est: 00m 00s Loss: 3.791\n","I0114 13:04:37.041453 140604169783168 train.py:351] Saving checkpoint for epoch 13 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-15\n","I0114 13:04:37.041669 140604169783168 train.py:304] \n","---------- Epoch 14/20 ----------\n","I0114 13:04:38.239506 140604169783168 train.py:326] Iteration 36800/56540: 40.94 it/s. Loss: 3.760\n","I0114 13:04:40.717115 140604169783168 train.py:326] Iteration 36900/56540: 40.55 it/s. Loss: 3.780\n","I0114 13:04:43.164816 140604169783168 train.py:326] Iteration 37000/56540: 40.67 it/s. Loss: 3.777\n","I0114 13:04:45.613587 140604169783168 train.py:326] Iteration 37100/56540: 40.72 it/s. Loss: 3.773\n","I0114 13:04:48.087556 140604169783168 train.py:326] Iteration 37200/56540: 40.65 it/s. Loss: 3.779\n","I0114 13:04:50.547991 140604169783168 train.py:326] Iteration 37300/56540: 40.65 it/s. Loss: 3.777\n","I0114 13:04:53.025732 140604169783168 train.py:326] Iteration 37400/56540: 40.61 it/s. Loss: 3.779\n","I0114 13:04:55.499798 140604169783168 train.py:326] Iteration 37500/56540: 40.58 it/s. Loss: 3.780\n","I0114 13:04:57.992675 140604169783168 train.py:326] Iteration 37600/56540: 40.52 it/s. Loss: 3.777\n","I0114 13:05:00.454768 140604169783168 train.py:326] Iteration 37700/56540: 40.53 it/s. Loss: 3.782\n","I0114 13:05:02.904986 140604169783168 train.py:326] Iteration 37800/56540: 40.56 it/s. Loss: 3.784\n","I0114 13:05:05.372706 140604169783168 train.py:326] Iteration 37900/56540: 40.56 it/s. Loss: 3.781\n","I0114 13:05:07.852334 140604169783168 train.py:326] Iteration 38000/56540: 40.54 it/s. Loss: 3.779\n","I0114 13:05:10.327591 140604169783168 train.py:326] Iteration 38100/56540: 40.53 it/s. Loss: 3.781\n","I0114 13:05:12.765203 140604169783168 train.py:326] Iteration 38200/56540: 40.56 it/s. Loss: 3.783\n","I0114 13:05:15.243701 140604169783168 train.py:326] Iteration 38300/56540: 40.55 it/s. Loss: 3.784\n","I0114 13:05:17.689621 140604169783168 train.py:326] Iteration 38400/56540: 40.57 it/s. Loss: 3.788\n","I0114 13:05:20.150529 140604169783168 train.py:326] Iteration 38500/56540: 40.57 it/s. Loss: 3.788\n","I0114 13:05:22.631127 140604169783168 train.py:326] Iteration 38600/56540: 40.56 it/s. Loss: 3.788\n","I0114 13:05:25.062550 140604169783168 train.py:326] Iteration 38700/56540: 40.59 it/s. Loss: 3.786\n","I0114 13:05:27.538284 140604169783168 train.py:326] Iteration 38800/56540: 40.58 it/s. Loss: 3.783\n","I0114 13:05:29.972430 140604169783168 train.py:326] Iteration 38900/56540: 40.60 it/s. Loss: 3.779\n","I0114 13:05:32.426440 140604169783168 train.py:326] Iteration 39000/56540: 40.61 it/s. Loss: 3.777\n","I0114 13:05:34.876218 140604169783168 train.py:326] Iteration 39100/56540: 40.62 it/s. Loss: 3.778\n","I0114 13:05:37.353904 140604169783168 train.py:326] Iteration 39200/56540: 40.61 it/s. Loss: 3.776\n","I0114 13:05:39.823761 140604169783168 train.py:326] Iteration 39300/56540: 40.60 it/s. Loss: 3.775\n","I0114 13:05:42.368845 140604169783168 train.py:326] Iteration 39400/56540: 40.55 it/s. Loss: 3.775\n","I0114 13:05:44.853846 140604169783168 train.py:326] Iteration 39500/56540: 40.54 it/s. Loss: 3.776\n","Iteration 2827/2827: [==========>] 40.52 it/s. Est: 00m 00s Loss: 3.774\n","I0114 13:05:49.758023 140604169783168 train.py:351] Saving checkpoint for epoch 14 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-16\n","I0114 13:05:49.758244 140604169783168 train.py:304] \n","---------- Epoch 15/20 ----------\n","I0114 13:05:50.311379 140604169783168 train.py:326] Iteration 39600/56540: 39.84 it/s. Loss: 3.724\n","I0114 13:05:52.744477 140604169783168 train.py:326] Iteration 39700/56540: 40.87 it/s. Loss: 3.763\n","I0114 13:05:55.191316 140604169783168 train.py:326] Iteration 39800/56540: 40.87 it/s. Loss: 3.770\n","I0114 13:05:57.633038 140604169783168 train.py:326] Iteration 39900/56540: 40.89 it/s. Loss: 3.760\n","I0114 13:06:00.116420 140604169783168 train.py:326] Iteration 40000/56540: 40.74 it/s. Loss: 3.762\n","I0114 13:06:02.589516 140604169783168 train.py:326] Iteration 40100/56540: 40.69 it/s. Loss: 3.763\n","I0114 13:06:05.055107 140604169783168 train.py:326] Iteration 40200/56540: 40.66 it/s. Loss: 3.762\n","I0114 13:06:07.528979 140604169783168 train.py:326] Iteration 40300/56540: 40.63 it/s. Loss: 3.764\n","I0114 13:06:09.975987 140604169783168 train.py:326] Iteration 40400/56540: 40.66 it/s. Loss: 3.763\n","I0114 13:06:12.435096 140604169783168 train.py:326] Iteration 40500/56540: 40.66 it/s. Loss: 3.766\n","I0114 13:06:14.865594 140604169783168 train.py:326] Iteration 40600/56540: 40.71 it/s. Loss: 3.769\n","I0114 13:06:17.394286 140604169783168 train.py:326] Iteration 40700/56540: 40.60 it/s. Loss: 3.768\n","I0114 13:06:19.847808 140604169783168 train.py:326] Iteration 40800/56540: 40.61 it/s. Loss: 3.765\n","I0114 13:06:22.323957 140604169783168 train.py:326] Iteration 40900/56540: 40.60 it/s. Loss: 3.767\n","I0114 13:06:24.784609 140604169783168 train.py:326] Iteration 41000/56540: 40.60 it/s. Loss: 3.768\n","I0114 13:06:27.234082 140604169783168 train.py:326] Iteration 41100/56540: 40.61 it/s. Loss: 3.769\n","I0114 13:06:29.721770 140604169783168 train.py:326] Iteration 41200/56540: 40.59 it/s. Loss: 3.771\n","I0114 13:06:32.181561 140604169783168 train.py:326] Iteration 41300/56540: 40.59 it/s. Loss: 3.774\n","I0114 13:06:34.648659 140604169783168 train.py:326] Iteration 41400/56540: 40.59 it/s. Loss: 3.774\n","I0114 13:06:37.104159 140604169783168 train.py:326] Iteration 41500/56540: 40.60 it/s. Loss: 3.773\n","I0114 13:06:39.564234 140604169783168 train.py:326] Iteration 41600/56540: 40.60 it/s. Loss: 3.770\n","I0114 13:06:42.036579 140604169783168 train.py:326] Iteration 41700/56540: 40.59 it/s. Loss: 3.766\n","I0114 13:06:44.504588 140604169783168 train.py:326] Iteration 41800/56540: 40.59 it/s. Loss: 3.763\n","I0114 13:06:46.984076 140604169783168 train.py:326] Iteration 41900/56540: 40.58 it/s. Loss: 3.765\n","I0114 13:06:49.493621 140604169783168 train.py:326] Iteration 42000/56540: 40.55 it/s. Loss: 3.763\n","I0114 13:06:51.968764 140604169783168 train.py:326] Iteration 42100/56540: 40.54 it/s. Loss: 3.762\n","I0114 13:06:54.458980 140604169783168 train.py:326] Iteration 42200/56540: 40.53 it/s. Loss: 3.761\n","I0114 13:06:56.906502 140604169783168 train.py:326] Iteration 42300/56540: 40.54 it/s. Loss: 3.762\n","I0114 13:06:59.379929 140604169783168 train.py:326] Iteration 42400/56540: 40.53 it/s. Loss: 3.761\n","Iteration 2827/2827: [==========>] 40.53 it/s. Est: 00m 00s Loss: 3.761\n","I0114 13:07:02.459321 140604169783168 train.py:351] Saving checkpoint for epoch 15 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-17\n","I0114 13:07:02.459529 140604169783168 train.py:304] \n","---------- Epoch 16/20 ----------\n","I0114 13:07:04.870247 140604169783168 train.py:326] Iteration 42500/56540: 39.42 it/s. Loss: 3.745\n","I0114 13:07:07.462468 140604169783168 train.py:326] Iteration 42600/56540: 38.99 it/s. Loss: 3.757\n","I0114 13:07:09.977963 140604169783168 train.py:326] Iteration 42700/56540: 39.24 it/s. Loss: 3.755\n","I0114 13:07:12.477288 140604169783168 train.py:326] Iteration 42800/56540: 39.43 it/s. Loss: 3.749\n","I0114 13:07:14.918481 140604169783168 train.py:326] Iteration 42900/56540: 39.73 it/s. Loss: 3.751\n","I0114 13:07:17.411853 140604169783168 train.py:326] Iteration 43000/56540: 39.80 it/s. Loss: 3.751\n","I0114 13:07:19.868823 140604169783168 train.py:326] Iteration 43100/56540: 39.92 it/s. Loss: 3.754\n","I0114 13:07:22.367571 140604169783168 train.py:326] Iteration 43200/56540: 39.94 it/s. Loss: 3.755\n","I0114 13:07:24.812680 140604169783168 train.py:326] Iteration 43300/56540: 40.04 it/s. Loss: 3.755\n","I0114 13:07:27.269478 140604169783168 train.py:326] Iteration 43400/56540: 40.11 it/s. Loss: 3.758\n","I0114 13:07:29.701446 140604169783168 train.py:326] Iteration 43500/56540: 40.20 it/s. Loss: 3.758\n","I0114 13:07:32.161778 140604169783168 train.py:326] Iteration 43600/56540: 40.23 it/s. Loss: 3.754\n","I0114 13:07:34.617052 140604169783168 train.py:326] Iteration 43700/56540: 40.27 it/s. Loss: 3.756\n","I0114 13:07:37.067064 140604169783168 train.py:326] Iteration 43800/56540: 40.31 it/s. Loss: 3.757\n","I0114 13:07:39.536760 140604169783168 train.py:326] Iteration 43900/56540: 40.32 it/s. Loss: 3.759\n","I0114 13:07:42.031510 140604169783168 train.py:326] Iteration 44000/56540: 40.31 it/s. Loss: 3.760\n","I0114 13:07:44.505397 140604169783168 train.py:326] Iteration 44100/56540: 40.31 it/s. Loss: 3.764\n","I0114 13:07:46.965013 140604169783168 train.py:326] Iteration 44200/56540: 40.33 it/s. Loss: 3.764\n","I0114 13:07:49.436145 140604169783168 train.py:326] Iteration 44300/56540: 40.34 it/s. Loss: 3.763\n","I0114 13:07:51.955590 140604169783168 train.py:326] Iteration 44400/56540: 40.31 it/s. Loss: 3.760\n","I0114 13:07:54.456146 140604169783168 train.py:326] Iteration 44500/56540: 40.29 it/s. Loss: 3.757\n","I0114 13:07:56.981975 140604169783168 train.py:326] Iteration 44600/56540: 40.26 it/s. Loss: 3.754\n","I0114 13:07:59.524000 140604169783168 train.py:326] Iteration 44700/56540: 40.22 it/s. Loss: 3.754\n","I0114 13:08:01.990021 140604169783168 train.py:326] Iteration 44800/56540: 40.23 it/s. Loss: 3.753\n","I0114 13:08:04.485722 140604169783168 train.py:326] Iteration 44900/56540: 40.23 it/s. Loss: 3.752\n","I0114 13:08:06.930167 140604169783168 train.py:326] Iteration 45000/56540: 40.25 it/s. Loss: 3.752\n","I0114 13:08:09.399653 140604169783168 train.py:326] Iteration 45100/56540: 40.26 it/s. Loss: 3.752\n","I0114 13:08:11.848161 140604169783168 train.py:326] Iteration 45200/56540: 40.28 it/s. Loss: 3.752\n","Iteration 2827/2827: [==========>] 40.29 it/s. Est: 00m 00s Loss: 3.751\n","I0114 13:08:15.591933 140604169783168 train.py:351] Saving checkpoint for epoch 16 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-18\n","I0114 13:08:15.592177 140604169783168 train.py:304] \n","---------- Epoch 17/20 ----------\n","I0114 13:08:17.278326 140604169783168 train.py:326] Iteration 45300/56540: 40.35 it/s. Loss: 3.729\n","I0114 13:08:19.763285 140604169783168 train.py:326] Iteration 45400/56540: 40.29 it/s. Loss: 3.745\n","I0114 13:08:22.259972 140604169783168 train.py:326] Iteration 45500/56540: 40.20 it/s. Loss: 3.741\n","I0114 13:08:24.720775 140604169783168 train.py:326] Iteration 45600/56540: 40.32 it/s. Loss: 3.738\n","I0114 13:08:27.197903 140604169783168 train.py:326] Iteration 45700/56540: 40.33 it/s. Loss: 3.743\n","I0114 13:08:29.668022 140604169783168 train.py:326] Iteration 45800/56540: 40.36 it/s. Loss: 3.743\n","I0114 13:08:32.135371 140604169783168 train.py:326] Iteration 45900/56540: 40.38 it/s. Loss: 3.745\n","I0114 13:08:34.606046 140604169783168 train.py:326] Iteration 46000/56540: 40.39 it/s. Loss: 3.746\n","I0114 13:08:37.087366 140604169783168 train.py:326] Iteration 46100/56540: 40.38 it/s. Loss: 3.745\n","I0114 13:08:39.566464 140604169783168 train.py:326] Iteration 46200/56540: 40.38 it/s. Loss: 3.750\n","I0114 13:08:42.058507 140604169783168 train.py:326] Iteration 46300/56540: 40.35 it/s. Loss: 3.751\n","I0114 13:08:44.530584 140604169783168 train.py:326] Iteration 46400/56540: 40.36 it/s. Loss: 3.748\n","I0114 13:08:47.050213 140604169783168 train.py:326] Iteration 46500/56540: 40.31 it/s. Loss: 3.747\n","I0114 13:08:49.505158 140604169783168 train.py:326] Iteration 46600/56540: 40.34 it/s. Loss: 3.749\n","I0114 13:08:51.961323 140604169783168 train.py:326] Iteration 46700/56540: 40.37 it/s. Loss: 3.752\n","I0114 13:08:54.427063 140604169783168 train.py:326] Iteration 46800/56540: 40.38 it/s. Loss: 3.752\n","I0114 13:08:56.895054 140604169783168 train.py:326] Iteration 46900/56540: 40.39 it/s. Loss: 3.757\n","I0114 13:08:59.329409 140604169783168 train.py:326] Iteration 47000/56540: 40.42 it/s. Loss: 3.757\n","I0114 13:09:01.837676 140604169783168 train.py:326] Iteration 47100/56540: 40.39 it/s. Loss: 3.757\n","I0114 13:09:04.310114 140604169783168 train.py:326] Iteration 47200/56540: 40.40 it/s. Loss: 3.754\n","I0114 13:09:06.747835 140604169783168 train.py:326] Iteration 47300/56540: 40.43 it/s. Loss: 3.751\n","I0114 13:09:09.203107 140604169783168 train.py:326] Iteration 47400/56540: 40.44 it/s. Loss: 3.748\n","I0114 13:09:11.671539 140604169783168 train.py:326] Iteration 47500/56540: 40.44 it/s. Loss: 3.747\n","I0114 13:09:14.128424 140604169783168 train.py:326] Iteration 47600/56540: 40.45 it/s. Loss: 3.747\n","I0114 13:09:16.589520 140604169783168 train.py:326] Iteration 47700/56540: 40.46 it/s. Loss: 3.746\n","I0114 13:09:19.104438 140604169783168 train.py:326] Iteration 47800/56540: 40.43 it/s. Loss: 3.745\n","I0114 13:09:21.586679 140604169783168 train.py:326] Iteration 47900/56540: 40.43 it/s. Loss: 3.746\n","I0114 13:09:24.053306 140604169783168 train.py:326] Iteration 48000/56540: 40.43 it/s. Loss: 3.746\n","Iteration 2827/2827: [==========>] 40.44 it/s. Est: 00m 00s Loss: 3.745\n","I0114 13:09:28.460942 140604169783168 train.py:351] Saving checkpoint for epoch 17 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-19\n","I0114 13:09:28.461155 140604169783168 train.py:304] \n","---------- Epoch 18/20 ----------\n","I0114 13:09:29.481656 140604169783168 train.py:326] Iteration 48100/56540: 40.21 it/s. Loss: 3.710\n","I0114 13:09:31.928313 140604169783168 train.py:326] Iteration 48200/56540: 40.68 it/s. Loss: 3.738\n","I0114 13:09:34.444658 140604169783168 train.py:326] Iteration 48300/56540: 40.28 it/s. Loss: 3.739\n","I0114 13:09:36.940616 140604169783168 train.py:326] Iteration 48400/56540: 40.22 it/s. Loss: 3.730\n","I0114 13:09:39.471250 140604169783168 train.py:326] Iteration 48500/56540: 40.06 it/s. Loss: 3.738\n","I0114 13:09:41.984883 140604169783168 train.py:326] Iteration 48600/56540: 40.01 it/s. Loss: 3.735\n","I0114 13:09:44.504441 140604169783168 train.py:326] Iteration 48700/56540: 39.96 it/s. Loss: 3.738\n","I0114 13:09:47.018959 140604169783168 train.py:326] Iteration 48800/56540: 39.93 it/s. Loss: 3.742\n","I0114 13:09:49.493084 140604169783168 train.py:326] Iteration 48900/56540: 39.99 it/s. Loss: 3.739\n","I0114 13:09:51.957959 140604169783168 train.py:326] Iteration 49000/56540: 40.05 it/s. Loss: 3.743\n","I0114 13:09:54.453807 140604169783168 train.py:326] Iteration 49100/56540: 40.05 it/s. Loss: 3.746\n","I0114 13:09:56.930962 140604169783168 train.py:326] Iteration 49200/56540: 40.08 it/s. Loss: 3.745\n","I0114 13:09:59.388950 140604169783168 train.py:326] Iteration 49300/56540: 40.13 it/s. Loss: 3.742\n","I0114 13:10:01.882957 140604169783168 train.py:326] Iteration 49400/56540: 40.12 it/s. Loss: 3.744\n","I0114 13:10:04.354145 140604169783168 train.py:326] Iteration 49500/56540: 40.15 it/s. Loss: 3.746\n","I0114 13:10:06.894283 140604169783168 train.py:326] Iteration 49600/56540: 40.10 it/s. Loss: 3.747\n","I0114 13:10:09.353170 140604169783168 train.py:326] Iteration 49700/56540: 40.13 it/s. Loss: 3.750\n","I0114 13:10:11.825779 140604169783168 train.py:326] Iteration 49800/56540: 40.15 it/s. Loss: 3.752\n","I0114 13:10:14.285102 140604169783168 train.py:326] Iteration 49900/56540: 40.18 it/s. Loss: 3.752\n","I0114 13:10:16.757005 140604169783168 train.py:326] Iteration 50000/56540: 40.19 it/s. Loss: 3.750\n","I0114 13:10:19.204766 140604169783168 train.py:326] Iteration 50100/56540: 40.22 it/s. Loss: 3.747\n","I0114 13:10:21.635149 140604169783168 train.py:326] Iteration 50200/56540: 40.26 it/s. Loss: 3.744\n","I0114 13:10:24.118347 140604169783168 train.py:326] Iteration 50300/56540: 40.27 it/s. Loss: 3.742\n","I0114 13:10:26.591709 140604169783168 train.py:326] Iteration 50400/56540: 40.27 it/s. Loss: 3.743\n","I0114 13:10:29.053792 140604169783168 train.py:326] Iteration 50500/56540: 40.29 it/s. Loss: 3.741\n","I0114 13:10:31.527923 140604169783168 train.py:326] Iteration 50600/56540: 40.29 it/s. Loss: 3.740\n","I0114 13:10:33.995512 140604169783168 train.py:326] Iteration 50700/56540: 40.30 it/s. Loss: 3.741\n","I0114 13:10:36.461921 140604169783168 train.py:326] Iteration 50800/56540: 40.31 it/s. Loss: 3.742\n","Iteration 2827/2827: [==========>] 40.28 it/s. Est: 00m 00s Loss: 3.741\n","I0114 13:10:41.697720 140604169783168 train.py:351] Saving checkpoint for epoch 18 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-20\n","I0114 13:10:41.697949 140604169783168 train.py:304] \n","---------- Epoch 19/20 ----------\n","I0114 13:10:42.055105 140604169783168 train.py:326] Iteration 50900/56540: 39.30 it/s. Loss: 3.697\n","I0114 13:10:44.562929 140604169783168 train.py:326] Iteration 51000/56540: 39.80 it/s. Loss: 3.731\n","I0114 13:10:47.055391 140604169783168 train.py:326] Iteration 51100/56540: 39.95 it/s. Loss: 3.739\n","I0114 13:10:49.575994 140604169783168 train.py:326] Iteration 51200/56540: 39.86 it/s. Loss: 3.733\n","I0114 13:10:52.052480 140604169783168 train.py:326] Iteration 51300/56540: 39.99 it/s. Loss: 3.734\n","I0114 13:10:54.611591 140604169783168 train.py:326] Iteration 51400/56540: 39.81 it/s. Loss: 3.734\n","I0114 13:10:57.079545 140604169783168 train.py:326] Iteration 51500/56540: 39.92 it/s. Loss: 3.735\n","I0114 13:10:59.577339 140604169783168 train.py:326] Iteration 51600/56540: 39.94 it/s. Loss: 3.738\n","I0114 13:11:02.040368 140604169783168 train.py:326] Iteration 51700/56540: 40.02 it/s. Loss: 3.739\n","I0114 13:11:04.530532 140604169783168 train.py:326] Iteration 51800/56540: 40.03 it/s. Loss: 3.740\n","I0114 13:11:07.023365 140604169783168 train.py:326] Iteration 51900/56540: 40.04 it/s. Loss: 3.744\n","I0114 13:11:09.527266 140604169783168 train.py:326] Iteration 52000/56540: 40.03 it/s. Loss: 3.743\n","I0114 13:11:11.995072 140604169783168 train.py:326] Iteration 52100/56540: 40.07 it/s. Loss: 3.740\n","I0114 13:11:14.526732 140604169783168 train.py:326] Iteration 52200/56540: 40.03 it/s. Loss: 3.742\n","I0114 13:11:16.996651 140604169783168 train.py:326] Iteration 52300/56540: 40.06 it/s. Loss: 3.743\n","I0114 13:11:19.434361 140604169783168 train.py:326] Iteration 52400/56540: 40.12 it/s. Loss: 3.744\n","I0114 13:11:21.924100 140604169783168 train.py:326] Iteration 52500/56540: 40.12 it/s. Loss: 3.746\n","I0114 13:11:24.366961 140604169783168 train.py:326] Iteration 52600/56540: 40.17 it/s. Loss: 3.750\n","I0114 13:11:26.844841 140604169783168 train.py:326] Iteration 52700/56540: 40.18 it/s. Loss: 3.750\n","I0114 13:11:29.288059 140604169783168 train.py:326] Iteration 52800/56540: 40.22 it/s. Loss: 3.748\n","I0114 13:11:31.756121 140604169783168 train.py:326] Iteration 52900/56540: 40.23 it/s. Loss: 3.746\n","I0114 13:11:34.290682 140604169783168 train.py:326] Iteration 53000/56540: 40.20 it/s. Loss: 3.742\n","I0114 13:11:36.766447 140604169783168 train.py:326] Iteration 53100/56540: 40.21 it/s. Loss: 3.740\n","I0114 13:11:39.229646 140604169783168 train.py:326] Iteration 53200/56540: 40.22 it/s. Loss: 3.741\n","I0114 13:11:41.740153 140604169783168 train.py:326] Iteration 53300/56540: 40.21 it/s. Loss: 3.740\n","I0114 13:11:44.230565 140604169783168 train.py:326] Iteration 53400/56540: 40.20 it/s. Loss: 3.739\n","I0114 13:11:46.713426 140604169783168 train.py:326] Iteration 53500/56540: 40.21 it/s. Loss: 3.738\n","I0114 13:11:49.209929 140604169783168 train.py:326] Iteration 53600/56540: 40.20 it/s. Loss: 3.739\n","I0114 13:11:51.691037 140604169783168 train.py:326] Iteration 53700/56540: 40.20 it/s. Loss: 3.739\n","Iteration 2827/2827: [==========>] 40.21 it/s. Est: 00m 00s Loss: 3.739\n","I0114 13:11:54.978457 140604169783168 train.py:351] Saving checkpoint for epoch 19 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-21\n","I0114 13:11:54.978662 140604169783168 train.py:304] \n","---------- Epoch 20/20 ----------\n","I0114 13:11:57.142510 140604169783168 train.py:326] Iteration 53800/56540: 40.22 it/s. Loss: 3.721\n","I0114 13:11:59.618137 140604169783168 train.py:326] Iteration 53900/56540: 40.32 it/s. Loss: 3.736\n","I0114 13:12:02.147197 140604169783168 train.py:326] Iteration 54000/56540: 40.04 it/s. Loss: 3.733\n","I0114 13:12:04.621963 140604169783168 train.py:326] Iteration 54100/56540: 40.14 it/s. Loss: 3.728\n","I0114 13:12:07.087055 140604169783168 train.py:326] Iteration 54200/56540: 40.22 it/s. Loss: 3.733\n","I0114 13:12:09.573523 140604169783168 train.py:326] Iteration 54300/56540: 40.22 it/s. Loss: 3.731\n","I0114 13:12:12.065758 140604169783168 train.py:326] Iteration 54400/56540: 40.21 it/s. Loss: 3.735\n","I0114 13:12:14.531180 140604169783168 train.py:326] Iteration 54500/56540: 40.25 it/s. Loss: 3.736\n","I0114 13:12:17.009871 140604169783168 train.py:326] Iteration 54600/56540: 40.26 it/s. Loss: 3.736\n","I0114 13:12:19.537407 140604169783168 train.py:326] Iteration 54700/56540: 40.19 it/s. Loss: 3.740\n","I0114 13:12:22.015536 140604169783168 train.py:326] Iteration 54800/56540: 40.21 it/s. Loss: 3.741\n","I0114 13:12:24.504405 140604169783168 train.py:326] Iteration 54900/56540: 40.20 it/s. Loss: 3.737\n","I0114 13:12:26.973373 140604169783168 train.py:326] Iteration 55000/56540: 40.23 it/s. Loss: 3.738\n","I0114 13:12:29.418694 140604169783168 train.py:326] Iteration 55100/56540: 40.27 it/s. Loss: 3.740\n","I0114 13:12:31.891891 140604169783168 train.py:326] Iteration 55200/56540: 40.28 it/s. Loss: 3.742\n","I0114 13:12:34.348825 140604169783168 train.py:326] Iteration 55300/56540: 40.31 it/s. Loss: 3.743\n","I0114 13:12:36.784027 140604169783168 train.py:326] Iteration 55400/56540: 40.35 it/s. Loss: 3.747\n","I0114 13:12:39.277023 140604169783168 train.py:326] Iteration 55500/56540: 40.34 it/s. Loss: 3.748\n","I0114 13:12:41.756060 140604169783168 train.py:326] Iteration 55600/56540: 40.34 it/s. Loss: 3.747\n","I0114 13:12:44.243447 140604169783168 train.py:326] Iteration 55700/56540: 40.33 it/s. Loss: 3.744\n","I0114 13:12:46.731906 140604169783168 train.py:326] Iteration 55800/56540: 40.33 it/s. Loss: 3.741\n","I0114 13:12:49.183123 140604169783168 train.py:326] Iteration 55900/56540: 40.35 it/s. Loss: 3.738\n","I0114 13:12:51.651425 140604169783168 train.py:326] Iteration 56000/56540: 40.36 it/s. Loss: 3.738\n","I0114 13:12:54.133129 140604169783168 train.py:326] Iteration 56100/56540: 40.35 it/s. Loss: 3.738\n","I0114 13:12:56.645989 140604169783168 train.py:326] Iteration 56200/56540: 40.33 it/s. Loss: 3.737\n","I0114 13:12:59.100486 140604169783168 train.py:326] Iteration 56300/56540: 40.35 it/s. Loss: 3.737\n","I0114 13:13:01.640967 140604169783168 train.py:326] Iteration 56400/56540: 40.31 it/s. Loss: 3.737\n","I0114 13:13:04.164718 140604169783168 train.py:326] Iteration 56500/56540: 40.28 it/s. Loss: 3.737\n","Iteration 2827/2827: [==========>] 40.28 it/s. Est: 00m 00s Loss: 3.737\n","I0114 13:13:08.177467 140604169783168 train.py:351] Saving checkpoint for epoch 20 at ./checkpoints/train/dmodel128_dffn512_blocks6/ckpt-22\n","I0114 13:13:08.177677 140604169783168 train.py:356] ****************************************************************************************************\n","\n","TRAINING COMPLETE.\n","\n","****************************************************************************************************\n","I0114 13:13:08.177829 140604169783168 train.py:361] Saving final model to saved_models/dmodel128_dffn512_blocks6\n","E0114 13:13:08.264001 140604169783168 train.py:365] Failed to save model\n","E0114 13:13:08.264164 140604169783168 train.py:366] ('in user code:\\n\\n    File \"/usr/local/lib/python3.7/dist-packages/keras/saving/saving_utils.py\", line 125, in _wrapped_model  *\\n        outputs = model(*args, **kwargs)\\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\\n        raise e.with_traceback(filtered_tb) from None\\n\\n    TypeError: Exception encountered when calling layer \"par_transformer_xl\" (type PARTransformerXL).\\n    \\n    in user code:\\n    \\n        File \"/content/PAR-Transformer-XL/par_model.py\", line 273, in call  *\\n            new_mem = self._get_next_mem(x, x_mems[i], self.mem_len)\\n        File \"/content/PAR-Transformer-XL/par_model.py\", line 251, in _get_next_mem  *\\n            new_state = tf.concat([x_mem, x], 1)\\n    \\n        TypeError: Tensors in list passed to \\'values\\' of \\'ConcatV2\\' Op have types [int32, float32] that don\\'t all match.\\n    \\n    \\n    Call arguments received:\\n      • x=tf.Tensor(shape=(None, 32), dtype=int32)\\n      • x_mems=tf.Tensor(shape=(None, 32), dtype=int32)\\n      • labels=None\\n      • tau=None\\n      • training=False\\n      • pad_mask=None\\n',)\n","I0114 13:13:08.264357 140604169783168 train.py:367] \n","\n","Total time: 24min. 43sec.\n","\n","\n"]}],"source":["!./base_model.sh"]},{"cell_type":"code","source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"],"metadata":{"id":"ctcHhnXtlt73","executionInfo":{"status":"ok","timestamp":1642166349055,"user_tz":-420,"elapsed":364,"user":{"displayName":"StudywithT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12146472268166735958"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!rm -rf ./logs/ "],"metadata":{"id":"vWSRSvBblugV","executionInfo":{"status":"ok","timestamp":1642166351068,"user_tz":-420,"elapsed":548,"user":{"displayName":"StudywithT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12146472268166735958"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8HaBNTNavjTl","executionInfo":{"status":"ok","timestamp":1642166388463,"user_tz":-420,"elapsed":18824,"user":{"displayName":"StudywithT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12146472268166735958"}},"outputId":"ad6e2ec4-3e0d-4c09-f05c-7a3e991a6aab"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!tensorboard dev upload \\\n","  --logdir /content/drive/MyDrive/Study/NLP/PAR-Transformer-XL/logs/dmodel128_dffn512_blocks6/train\\\n","  --name \"(optional) My latest experiment\" \\\n","  --description \"(optional) Simple comparison of several hyperparameters\" \\\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3RzCyGnOlxPq","executionInfo":{"status":"ok","timestamp":1642166673928,"user_tz":-420,"elapsed":58650,"user":{"displayName":"StudywithT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12146472268166735958"}},"outputId":"f36b6a1a-741f-45f2-e8ef-fc66a0eabc56"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Upload started and will continue reading any new data as it's added to the logdir.\n","\n","To stop uploading, press Ctrl-C.\n","\n","New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/efR95Ga5SYiBq6GIOnlQfA/\n","\n","\u001b[1m[2022-01-14T13:23:37]\u001b[0m Started scanning logdir.\n","\u001b[1m[2022-01-14T13:24:32]\u001b[0m Total uploaded: 189259 scalars, 0 tensors, 0 binary objects\n","\u001b[2K\u001b[33mListening for new data in logdir...\u001b[0m\n","\n","Interrupted. View your TensorBoard at https://tensorboard.dev/experiment/efR95Ga5SYiBq6GIOnlQfA/\n"]}]},{"cell_type":"markdown","metadata":{"id":"z-WVYMdgZlhb"},"source":["## (Optional) Save results\n","\n","The checkpoints file can be a lot of data, so it's advised to not zip the whole thing (which is why it's commented out) but just take which checkpoints you want.\n","\n","If the code runs to completion (about 37m on a single GPU with default model settings), then you also have the option of downloading a .savedmodel file, which can be loaded into a fully functional model by executing ``` tf.keras.models.load_model('saved_models')```"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":433},"id":"ifMgLUW_Zlhb","executionInfo":{"status":"ok","timestamp":1642166065721,"user_tz":-420,"elapsed":11645,"user":{"displayName":"StudywithT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12146472268166735958"}},"outputId":"1225289d-6f73-4917-ee6c-1af7c6a5add4"},"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: logs/ (stored 0%)\n","  adding: logs/dmodel128_dffn512_blocks6/ (stored 0%)\n","  adding: logs/dmodel128_dffn512_blocks6/train/ (stored 0%)\n","  adding: logs/dmodel128_dffn512_blocks6/train/events.out.tfevents.1642164041.0a061e494cad.135.0.v2 (deflated 75%)\n","  adding: logs/dmodel128_dffn512_blocks6/train/events.out.tfevents.1642164504.0a061e494cad.236.0.v2 (deflated 76%)\n","  adding: logs/dmodel128_dffn512_blocks6/test/ (stored 0%)\n","  adding: logs/dmodel128_dffn512_blocks6/test/events.out.tfevents.1642164504.0a061e494cad.236.1.v2 (deflated 67%)\n","  adding: logs/dmodel128_dffn512_blocks6/test/events.out.tfevents.1642164041.0a061e494cad.135.1.v2 (deflated 5%)\n","  adding: plots/ (stored 0%)\n","  adding: checkpoints/ (stored 0%)\n","  adding: checkpoints/train/ (stored 0%)\n","  adding: checkpoints/train/dmodel128_dffn512_blocks6/ (stored 0%)\n","  adding: checkpoints/train/dmodel128_dffn512_blocks6/ckpt-20.data-00000-of-00001 (deflated 18%)\n","  adding: checkpoints/train/dmodel128_dffn512_blocks6/ckpt-18.index (deflated 80%)\n","  adding: checkpoints/train/dmodel128_dffn512_blocks6/ckpt-20.index (deflated 80%)\n","  adding: checkpoints/train/dmodel128_dffn512_blocks6/ckpt-22.data-00000-of-00001 (deflated 18%)\n","  adding: checkpoints/train/dmodel128_dffn512_blocks6/config.json (deflated 32%)\n","  adding: checkpoints/train/dmodel128_dffn512_blocks6/ckpt-21.index (deflated 80%)\n","  adding: checkpoints/train/dmodel128_dffn512_blocks6/ckpt-19.data-00000-of-00001 (deflated 18%)\n","  adding: checkpoints/train/dmodel128_dffn512_blocks6/ckpt-21.data-00000-of-00001 (deflated 18%)\n","  adding: checkpoints/train/dmodel128_dffn512_blocks6/ckpt-22.index (deflated 80%)\n","  adding: checkpoints/train/dmodel128_dffn512_blocks6/checkpoint (deflated 72%)\n","  adding: checkpoints/train/dmodel128_dffn512_blocks6/ckpt-18.data-00000-of-00001 (deflated 18%)\n","  adding: checkpoints/train/dmodel128_dffn512_blocks6/ckpt-19.index (deflated 80%)\n"]},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_733d147f-67b9-4d46-a3ff-da62e2dfb605\", \"plots.zip\", 162)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_44c1c018-18a8-4c2f-a7b3-0f29c204e88c\", \"logs.zip\", 3606561)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}],"source":["from google.colab import files\n","!zip -r logs.zip logs\n","!zip -r plots.zip plots\n","!zip -r checkpoints.zip checkpoints\n","\n","files.download('plots.zip')\n","files.download('logs.zip')"]},{"cell_type":"code","source":[""],"metadata":{"id":"f7Lhqz-ivYQB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WzEQrdLhZlhc"},"source":["## Interactive session\n","\n","Since this is a notebook, you can load in different checkpoints of the model (or the final version) and play around with it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0crEBD6bZlhc","executionInfo":{"status":"aborted","timestamp":1642160648307,"user_tz":-420,"elapsed":6,"user":{"displayName":"StudywithT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12146472268166735958"}}},"outputs":[],"source":["import os\n","import json\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_text as tf_text\n","import matplotlib.pyplot as plt\n","from data_utils import DataManager\n","from utils import visualize_pi_weights\n","from par_model import PARTransformerXL\n","from par_model import create_lookahead_mask, positional_encoding"]},{"cell_type":"markdown","metadata":{"id":"i8rsOuUNZlhd"},"source":["The below will work to load in from checkpoint. You have to \n","\n","1) recreate an identical model with the same architecture\n","\n","2) create a checkpoint object with parameter model=model. The key here was decided when the first model was checkpointed, i.e., that the model should always be called model.\n","\n","3) restore the checkpoint object with a checkpoint path ckpt.restore(PATH). This will automatically change the value of model globally, i.e. ckpt doesn't keep a copy of model, it keeps a reference.\n","\n","All that is in the load_from_checkpoint path. Have fun!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tyAhPQVIZlhd","executionInfo":{"status":"aborted","timestamp":1642160648308,"user_tz":-420,"elapsed":6,"user":{"displayName":"StudywithT","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12146472268166735958"}}},"outputs":[],"source":["def load_from_checkpoint(ckpt_path):\n","    with open(ckpt_path+'/config.json', 'r') as file:\n","        config = json.loads(file.readline())\n","    model = PARTransformerXL(**config)\n","    ckpt = tf.train.Checkpoint(model=model)\n","    ckpt_manager = tf.train.CheckpointManager(ckpt, ckpt_path, 5)\n","    ckpt.restore(ckpt_manager.latest_checkpoint)\n","    return model\n","\n","def load_from_savedmodel(path):\n","    return tf.keras.models.load_model(path)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"colab.ipynb","provenance":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}